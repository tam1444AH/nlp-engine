{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c3ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_written_date</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>review_from_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>out_of_helpful_count</th>\n",
       "      <th>customer_review_rating</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>amazon_verified_purchase</th>\n",
       "      <th>amazon_vine_program_review</th>\n",
       "      <th>review_with_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'R10019MUX6F9A'</td>\n",
       "      <td>'B00006881R'</td>\n",
       "      <td>'AWNC1GQ75W8K8'</td>\n",
       "      <td>'Works as advertised'</td>\n",
       "      <td>'2002-12-17'</td>\n",
       "      <td>'Neil'</td>\n",
       "      <td>'TeleZapper TZ 900 (Office Product)'</td>\n",
       "      <td>'I\\'ve had this product for about a month and ...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('R10019MUX6F9A', 'B00006881R', 'AWNC1GQ75W8K8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'R1002I943QCT20'</td>\n",
       "      <td>'B00471F0NK'</td>\n",
       "      <td>'A3SFG0OC59UXL5'</td>\n",
       "      <td>'macintosh version - bad graphics, bad interface'</td>\n",
       "      <td>'2007-06-05'</td>\n",
       "      <td>'D. Simons'</td>\n",
       "      <td>'null'</td>\n",
       "      <td>'I have been using the Macintosh OSX version o...</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('R1002I943QCT20', 'B00471F0NK', 'A3SFG0OC59UX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'R1003RILN06MX1'</td>\n",
       "      <td>'B0027U258Q'</td>\n",
       "      <td>'A2IP26LJGTJXSV'</td>\n",
       "      <td>'Great Software'</td>\n",
       "      <td>'2010-12-05'</td>\n",
       "      <td>'Tex'</td>\n",
       "      <td>'Paragon Partition Manager 10 Personal Edition...</td>\n",
       "      <td>'The Partition Manager is a great product. It\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>('R1003RILN06MX1', 'B0027U258Q', 'A2IP26LJGTJX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'R100523NBIQIEV'</td>\n",
       "      <td>'B000070MRB'</td>\n",
       "      <td>'A2DKAPBHZ5DERR'</td>\n",
       "      <td>'Neutral'</td>\n",
       "      <td>'2004-06-07'</td>\n",
       "      <td>'S. Barnes'</td>\n",
       "      <td>'Game Programming Starter Kit 6.0 (CD-ROM)'</td>\n",
       "      <td>'If you plan on getting this program go to htt...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('R100523NBIQIEV', 'B000070MRB', 'A2DKAPBHZ5DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'R1006KJEGKGV0O'</td>\n",
       "      <td>'B001B19D7I'</td>\n",
       "      <td>'AMZ7EO048MCWK'</td>\n",
       "      <td>'Great seat, but don\\'t like the buckle'</td>\n",
       "      <td>'2009-07-07'</td>\n",
       "      <td>'Cyrca'</td>\n",
       "      <td>'Britax Boulevard 65 TSIP Convertible Car Seat...</td>\n",
       "      <td>'I researched for months (on-line and in store...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('R1006KJEGKGV0O', 'B001B19D7I', 'AMZ7EO048MCW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          review_id    product_id       customer_id  \\\n",
       "0   'R10019MUX6F9A'  'B00006881R'   'AWNC1GQ75W8K8'   \n",
       "1  'R1002I943QCT20'  'B00471F0NK'  'A3SFG0OC59UXL5'   \n",
       "2  'R1003RILN06MX1'  'B0027U258Q'  'A2IP26LJGTJXSV'   \n",
       "3  'R100523NBIQIEV'  'B000070MRB'  'A2DKAPBHZ5DERR'   \n",
       "4  'R1006KJEGKGV0O'  'B001B19D7I'   'AMZ7EO048MCWK'   \n",
       "\n",
       "                                        review_title review_written_date  \\\n",
       "0                              'Works as advertised'        '2002-12-17'   \n",
       "1  'macintosh version - bad graphics, bad interface'        '2007-06-05'   \n",
       "2                                   'Great Software'        '2010-12-05'   \n",
       "3                                          'Neutral'        '2004-06-07'   \n",
       "4           'Great seat, but don\\'t like the buckle'        '2009-07-07'   \n",
       "\n",
       "  customer_name                                  review_from_title  \\\n",
       "0        'Neil'               'TeleZapper TZ 900 (Office Product)'   \n",
       "1   'D. Simons'                                             'null'   \n",
       "2         'Tex'  'Paragon Partition Manager 10 Personal Edition...   \n",
       "3   'S. Barnes'        'Game Programming Starter Kit 6.0 (CD-ROM)'   \n",
       "4       'Cyrca'  'Britax Boulevard 65 TSIP Convertible Car Seat...   \n",
       "\n",
       "                                         review_text helpful_count  \\\n",
       "0  'I\\'ve had this product for about a month and ...             7   \n",
       "1  'I have been using the Macintosh OSX version o...            21   \n",
       "2  'The Partition Manager is a great product. It\\...             1   \n",
       "3  'If you plan on getting this program go to htt...            -1   \n",
       "4  'I researched for months (on-line and in store...             1   \n",
       "\n",
       "  out_of_helpful_count customer_review_rating number_of_comments  \\\n",
       "0                    7                      4                  0   \n",
       "1                   23                      2                  0   \n",
       "2                    1                      5                  0   \n",
       "3                   -1                      3                  0   \n",
       "4                    1                      5                  0   \n",
       "\n",
       "  amazon_verified_purchase amazon_vine_program_review  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        1                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "                                review_with_metadata  \n",
       "0  ('R10019MUX6F9A', 'B00006881R', 'AWNC1GQ75W8K8...  \n",
       "1  ('R1002I943QCT20', 'B00471F0NK', 'A3SFG0OC59UX...  \n",
       "2  ('R1003RILN06MX1', 'B0027U258Q', 'A2IP26LJGTJX...  \n",
       "3  ('R100523NBIQIEV', 'B000070MRB', 'A2DKAPBHZ5DE...  \n",
       "4  ('R1006KJEGKGV0O', 'B001B19D7I', 'AMZ7EO048MCW...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"../reviews_segment.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad62aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfefb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095d9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20c5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = df['review_text'].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba51a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153247\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_index = defaultdict(set)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    document_id = row[\"review_id\"].strip(\"'\")\n",
    "    \n",
    "    for word in set(row[\"cleaned_review\"].split()):\n",
    "        word_index[word].add(document_id)\n",
    "\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "809dad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_baseline(aspect, opinion, operator1, operator2, operator3, filepath): # This is the baseline boolean function\n",
    "    aspect_tokens = aspect.lower().split()\n",
    "    opinion_tokens = opinion.lower().split()\n",
    "    \n",
    "    a1 = aspect_tokens[0]\n",
    "    a2 = aspect_tokens[1] if len(aspect_tokens) > 1 else None\n",
    "    o1 = opinion_tokens[0] if len(opinion_tokens) > 0 else None\n",
    "    o2 = opinion_tokens[1] if len(opinion_tokens) > 1 else None\n",
    "\n",
    "    a1 = lemmatizer.lemmatize(a1)\n",
    "    a2 = lemmatizer.lemmatize(a2) if a2 else None\n",
    "    o1 = lemmatizer.lemmatize(o1) if o1 else None\n",
    "    o2 = lemmatizer.lemmatize(o2) if o2 else None\n",
    "    \n",
    "    if operator1 == \"AND\":\n",
    "        aspect_docs = word_index.get(a1, set()).intersection(word_index.get(a2, set()))\n",
    "    elif operator1 == \"OR\":\n",
    "        aspect_docs = word_index.get(a1, set()).union(word_index.get(a2, set()))\n",
    "    else:\n",
    "        aspect_docs = word_index.get(a1, set())\n",
    "\n",
    "    if operator2 == \"AND\":\n",
    "        opinion_docs = word_index.get(o1, set()).intersection(word_index.get(o2, set()))\n",
    "    elif operator2 == \"OR\":\n",
    "        opinion_docs = word_index.get(o1, set()).union(word_index.get(o2, set()))\n",
    "    else:\n",
    "        opinion_docs = word_index.get(o1, set())\n",
    "\n",
    "    if operator3 == \"AND\":\n",
    "        result_docs = aspect_docs.intersection(opinion_docs)\n",
    "    elif operator3 == \"OR\":\n",
    "        result_docs = aspect_docs.union(opinion_docs)\n",
    "    else:\n",
    "        result_docs = aspect_docs\n",
    "\n",
    "    with open(f\"../Outputs/Baseline/{filepath}\", \"w\") as f:\n",
    "        for document_id in result_docs:\n",
    "            f.write(f\"{document_id}\\n\")\n",
    "        \n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "139b6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = boolean_baseline(\"audio quality\", \"poor\", operator1=\"OR\", operator2=\"\", operator3=\"\", filepath=\"audio_quality_test1.txt\")\n",
    "results = boolean_baseline(\"audio quality\", \"poor\", operator1=\"OR\", operator2=\"\", operator3=\"AND\", filepath=\"audio_quality_test2.txt\")\n",
    "results = boolean_baseline(\"audio quality\", \"poor\", operator1=\"OR\", operator2=\"\", operator3=\"OR\", filepath=\"audio_quality_test3.txt\")\n",
    "\n",
    "results = boolean_baseline(\"wifi signal\", \"strong\", operator1=\"OR\", operator2=\"\", operator3=\"\", filepath=\"wifi_signal_test1.txt\")\n",
    "results = boolean_baseline(\"wifi signal\", \"strong\", operator1=\"OR\", operator2=\"\", operator3=\"AND\", filepath=\"wifi_signal_test2.txt\")\n",
    "results = boolean_baseline(\"wifi signal\", \"strong\", operator1=\"OR\", operator2=\"\", operator3=\"OR\", filepath=\"wifi_signal_test3.txt\")\n",
    "\n",
    "results = boolean_baseline(\"mouse button\", \"click problem\", operator1=\"OR\", operator2=\"OR\", operator3=\"\", filepath=\"mouse_button_test1.txt\")\n",
    "results = boolean_baseline(\"mouse button\", \"click problem\", operator1=\"OR\", operator2=\"OR\", operator3=\"AND\", filepath=\"mouse_button_test2.txt\")\n",
    "results = boolean_baseline(\"mouse button\", \"click problem\", operator1=\"OR\", operator2=\"OR\", operator3=\"OR\", filepath=\"mouse_button_test3.txt\")\n",
    "\n",
    "results = boolean_baseline(\"gps map\", \"useful\", operator1=\"OR\", operator2=\"\", operator3=\"\", filepath=\"gps_map_test1.txt\")\n",
    "results = boolean_baseline(\"gps map\", \"useful\", operator1=\"OR\", operator2=\"\", operator3=\"AND\", filepath=\"gps_map_test2.txt\")\n",
    "results = boolean_baseline(\"gps map\", \"useful\", operator1=\"OR\", operator2=\"\", operator3=\"OR\", filepath=\"gps_map_test3.txt\")\n",
    "\n",
    "results = boolean_baseline(\"image quality\", \"sharp\", operator1=\"OR\", operator2=\"\", operator3=\"\", filepath=\"image_quality_test1.txt\")\n",
    "results = boolean_baseline(\"image quality\", \"sharp\", operator1=\"OR\", operator2=\"\", operator3=\"AND\", filepath=\"image_quality_test2.txt\")\n",
    "results = boolean_baseline(\"image quality\", \"sharp\", operator1=\"OR\", operator2=\"\", operator3=\"OR\", filepath=\"image_quality_test3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e7454e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opinion_lexicon(positive_file=\"positive-words.txt\", negative_file=\"negative-words.txt\"):\n",
    "    positive_words = set()\n",
    "    negative_words = set()\n",
    "\n",
    "    with open(positive_file, 'r', encoding='utf-8', errors='ignore') as pos_file:\n",
    "        for line in pos_file:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(';'):\n",
    "                positive_words.add(line)\n",
    "    \n",
    "    with open(negative_file, 'r', encoding='utf-8', errors='ignore') as neg_file:\n",
    "        for line in neg_file:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(';'):\n",
    "                negative_words.add(line)\n",
    "    \n",
    "    return positive_words, negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3027347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of positive words: 2006\n",
      "Length of negative words: 4783\n",
      "Sample of positive words: ['glimmer', 'courage', 'amazement', 'applaud', 'luxury', 'eye-catching', 'concise', 'meticulously', 'civilize', 'pepped']\n",
      "Sample of negative words: ['unskilled', 'repulsing', 'carnage', 'unkindly', 'fickle', 'glum', 'outrages', 'bewilder', 'unrealistic', 'irked']\n"
     ]
    }
   ],
   "source": [
    "positive_words, negative_words = load_opinion_lexicon()\n",
    "\n",
    "print(f\"Length of positive words: {len(positive_words)}\")\n",
    "print(f\"Length of negative words: {len(negative_words)}\")\n",
    "\n",
    "print(\"Sample of positive words:\", list(positive_words)[:10])\n",
    "print(\"Sample of negative words:\", list(negative_words)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e9e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion_sentiment(opinion):\n",
    "\n",
    "    if opinion in positive_words:\n",
    "        return \"positive\"\n",
    "    elif opinion in negative_words:\n",
    "        return \"negative\"\n",
    "    \n",
    "\n",
    "    return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "555bcd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1(aspect, opinion, operator1, operator2, operator3, filepath):\n",
    "    aspect_tokens = aspect.lower().split()\n",
    "    opinion_tokens = opinion.lower().split()\n",
    "\n",
    "    a1 = aspect_tokens[0]\n",
    "    a2 = aspect_tokens[1] if len(aspect_tokens) > 1 else None\n",
    "    o1 = opinion_tokens[0] if len(opinion_tokens) > 0 else None\n",
    "    o2 = opinion_tokens[1] if len(opinion_tokens) > 1 else None\n",
    "\n",
    "    a1 = lemmatizer.lemmatize(a1)\n",
    "    a2 = lemmatizer.lemmatize(a2) if a2 else None\n",
    "    o1 = lemmatizer.lemmatize(o1) if o1 else None\n",
    "    o2 = lemmatizer.lemmatize(o2) if o2 else None\n",
    "\n",
    "    if operator1 == \"AND\":\n",
    "        aspect_docs = word_index.get(a1, set()).intersection(word_index.get(a2, set()))\n",
    "    elif operator1 == \"OR\":\n",
    "        aspect_docs = word_index.get(a1, set()).union(word_index.get(a2, set()))\n",
    "    else:\n",
    "        aspect_docs = word_index.get(a1, set())\n",
    "\n",
    "    if operator2 == \"AND\":\n",
    "        opinion_docs = word_index.get(o1, set()).intersection(word_index.get(o2, set()))\n",
    "    elif operator2 == \"OR\":\n",
    "        opinion_docs = word_index.get(o1, set()).union(word_index.get(o2, set()))\n",
    "    else:\n",
    "        opinion_docs = word_index.get(o1, set())\n",
    "\n",
    "    if operator3 == \"AND\":\n",
    "        result_docs = aspect_docs.intersection(opinion_docs)\n",
    "    elif operator3 == \"OR\":\n",
    "        result_docs = aspect_docs.union(opinion_docs)\n",
    "    else:\n",
    "        result_docs = aspect_docs\n",
    "\n",
    "    \n",
    "    sentiment = get_opinion_sentiment(o2) if len(opinion_tokens) > 1 else get_opinion_sentiment(o1)\n",
    "    \n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "\n",
    "    filtered_results = set()\n",
    "\n",
    "    for document_id in result_docs:\n",
    "        review = df[df['review_id'].str.strip(\"'\") == document_id]\n",
    "        if not review.empty:\n",
    "            rating = review['customer_review_rating']\n",
    "\n",
    "            rating = int(rating.values[0])\n",
    "            if sentiment == \"positive\" and rating > 3:\n",
    "                filtered_results.add(document_id)\n",
    "            elif sentiment == \"negative\" and rating <= 3:\n",
    "                filtered_results.add(document_id)\n",
    "            elif sentiment == \"neutral\":\n",
    "                filtered_results.add(document_id)\n",
    "                \n",
    "    with open(f\"../Outputs/AdvancedModel/{filepath}\", \"w\") as f:\n",
    "        for document_id in filtered_results:\n",
    "            f.write(f\"{document_id}\\n\")\n",
    "\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46beb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: negative\n",
      "Sentiment: positive\n",
      "Sentiment: negative\n",
      "Sentiment: positive\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "results = m1(\"audio quality\", \"poor\", operator1=\"AND\", operator2=\"\", operator3=\"AND\", filepath=\"audio_quality_m1_test4.txt\")\n",
    "\n",
    "results = m1(\"wifi signal\", \"strong\", operator1=\"AND\", operator2=\"\", operator3=\"AND\", filepath=\"wifi_signal_m1_test4.txt\")\n",
    "\n",
    "results = m1(\"mouse button\", \"click problem\", operator1=\"AND\", operator2=\"AND\", operator3=\"AND\", filepath=\"mouse_button_m1_test4.txt\")\n",
    "\n",
    "results = m1(\"gps map\", \"useful\", operator1=\"AND\", operator2=\"\", operator3=\"AND\", filepath=\"gps_map_m1_test4.txt\")\n",
    "\n",
    "results = m1(\"image quality\", \"sharp\", operator1=\"AND\", operator2=\"\", operator3=\"AND\", filepath=\"image_quality_m1_test4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "999a0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "def m2(aspect, opinion, filepath):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    bert_embeddings = pd.read_pickle(\"../data.pkl\")\n",
    "    embeddings = np.stack(bert_embeddings['embedding'].values)\n",
    "    bert_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "    threshold = 0.70\n",
    "    \n",
    "    target_sentence = f\"The {aspect} is {opinion}\"\n",
    "    \n",
    "    query_embeddings = bert_model.encode([target_sentence], convert_to_numpy=True, device=device)\n",
    "\n",
    "    cos_similarities = cosine_similarity(embeddings, query_embeddings).ravel()\n",
    "    matched_indices = np.where(cos_similarities >= threshold)[0]\n",
    "\n",
    "    opinion_tokens = opinion.lower().split()\n",
    "    \n",
    "    o1 = opinion_tokens[0] if len(opinion_tokens) > 0 else None\n",
    "    o2 = opinion_tokens[1] if len(opinion_tokens) > 1 else None\n",
    "\n",
    "    o1 = lemmatizer.lemmatize(o1) if o1 else None\n",
    "    o2 = lemmatizer.lemmatize(o2) if o2 else None\n",
    "\n",
    "    sentiment = get_opinion_sentiment(o2) if len(opinion_tokens) > 1 else get_opinion_sentiment(o1)\n",
    "\n",
    "    result_docs = set()\n",
    "    for index in matched_indices:\n",
    "        document_id = bert_embeddings.iloc[index]['document_id']\n",
    "        \n",
    "        review = df[df['review_id'].str.strip(\"'\") == document_id]\n",
    "        if not review.empty:\n",
    "\n",
    "            rating = review['customer_review_rating']\n",
    "\n",
    "            rating = int(rating.values[0])\n",
    "\n",
    "            if sentiment == \"positive\" and rating > 3:\n",
    "                result_docs.add(document_id)\n",
    "            elif sentiment == \"negative\" and rating <= 3:\n",
    "                result_docs.add(document_id)\n",
    "            elif sentiment == \"neutral\":\n",
    "                result_docs.add(document_id)\n",
    "                \n",
    "    with open(f\"../Outputs/AdvancedModel/{filepath}\", \"w\") as f:\n",
    "        for document_id in result_docs:\n",
    "            f.write(f\"{document_id}\\n\")\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f04d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = m2(\"audio quality\", \"poor\", filepath=\"audio_quality_m2_test4.txt\")\n",
    "\n",
    "results = m2(\"wifi signal\", \"strong\", filepath=\"wifi_signal_m2_test4.txt\")\n",
    "\n",
    "results = m2(\"mouse button\", \"click problem\", filepath=\"mouse_button_m2_test4.txt\")\n",
    "\n",
    "results = m2(\"gps map\", \"useful\", filepath=\"gps_map_m2_test4.txt\")\n",
    "\n",
    "results = m2(\"image quality\", \"sharp\", filepath=\"image_quality_m2_test4.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
